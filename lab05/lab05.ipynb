{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsnd8ck9-JhU"
      },
      "source": [
        "# Przetwarzanie języka naturalnego\n",
        "\n",
        "Obecnie najpopularniejsze model służące do przetwarzania języka naturalnego wykorzystują architekturę transformacyjną. Istnieje kilka bibliotek, implementujących tę architekturę, ale w kontekście NLP najczęściej wykorzystuje się [Huggingface transformers](https://huggingface.co/docs/transformers/index).\n",
        "\n",
        "Biblioteka ta poza samym [kodem źródłowym](https://github.com/huggingface/transformers), zawiera szereg innych elementów. Do najważniejszych z nich należą:\n",
        "* [modele](https://huggingface.co/models) - olbrzymia i ciągle rosnąca liczba gotowych modeli, których możemy użyć do rozwiązywania wielu problemów z dziedziny NLP (ale również w zakresie rozpoznawania mowy, czy przetwarzania obrazu),\n",
        "* [zbiory danych](https://huggingface.co/datasets) - bardzo duży katalog przydatnych zbiorów danych, które możemy w prosty sposób wykorzystać do trenowania własnych modeli NLP (oraz innych modeli)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCVKT9diUlqT"
      },
      "source": [
        "## Przygotowanie środowiska\n",
        "\n",
        "Trening modeli NLP wymaga dostępu do akceleratorów sprzętowych, przyspieszających uczenie sieci neuronowych. Jeśli nasz komputer nie jest wyposażony w GPU, to możemy skorzystać ze środowiska Google Colab. \n",
        "\n",
        "W tym środowisku możemy wybrać akcelerator spośród GPU i TPU. \n",
        "Sprawdźmy, czy mamy dostęp do środowiska wyposażonego w akcelerator NVidii:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8OgLsVgK0bK",
        "outputId": "2409e12f-3523-4aaa-a978-5a20dd10a20c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Dec 25 11:01:25 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    27W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iHWHwumLJy-"
      },
      "source": [
        "Jeśli akcelerator jest niedostępny (polecenie skończyło się błędem), to zmieniamy środowisko wykonawcze wybierając z menu \"Środowisko wykonawcze\" -> \"Zmień typ środowiska wykonawczego\" -> GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ_GoQx_K6sC"
      },
      "source": [
        "Następnie zainstalujemy wszystkie niezbędne biblioteki.\n",
        "Poza samą biblioteką `transformers`, instalujemy również biblioteki do zarządzania zbiorami danych `datasets`, bibliotekę definiującą wiele metryk wykorzystywanych w algorytmach AI `evaluate` oraz dodatkowe narzędzia takie jak `sacremoses` oraz `sentencepiece`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeJtMsvBJ48f",
        "outputId": "b0b728f0-b198-4cdb-cd37-a3be58236b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 14.6 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 65.7 MB/s \n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n",
            "\u001b[K     |████████████████████████████████| 452 kB 67.3 MB/s \n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 12.5 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 62.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 65.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 75.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses) (1.2.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 79.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 79.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 78.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=d7e67cfd2dd66fa3d34b1db8528a789fdc917dc97d442e7ab9805c65ad38e13d\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: urllib3, xxhash, responses, multiprocess, huggingface-hub, tokenizers, datasets, transformers, sentencepiece, sacremoses, evaluate\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.8.0 evaluate-0.4.0 huggingface-hub-0.11.1 multiprocess-0.70.14 responses-0.18.0 sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.25.1 urllib3-1.25.11 xxhash-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers sacremoses datasets evaluate sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJunO6pV_tRK"
      },
      "source": [
        "Mając zainstalowane niezbedne bilioteki, możemy skorzystać z wszystkich modeli i zbiorów danych zarejestrowanych w katalogu. \n",
        "\n",
        "Typowym sposobem użycia dostępnych modeli jest:\n",
        "* *wykorzystanie gotowego modelu*, który realizuje określone zadanie, np. [analizę senetymentu w języku angielskim](https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis) - model tego rodzaju nie musi być trenowywany, wystarczy go uruchomić aby uzyskać wynik klasyfikacji (można to zobaczyć w demo pod wskazanym linkiem),\n",
        "* *wykorzystanie modelu bazowego*, który jest dotrenowywany do określonego zadania; przykładem takiego modelu jest [HerBERT base](https://huggingface.co/allegro/herbert-base-cased), który uczony był jako maskowany model języka. Żeby wykorzystać go do konkretnego zadania, musimy wybrać dla niego \"głowę klasyfikacyjną\" oraz dotrenować na własnym zbiorze danych.\n",
        "\n",
        "Modele tego rodzaju różnią się od siebie, można je załadować za pomocą wspólnego interfejsu, ale najlepiej jest wykorzystać jedną ze specjalizowanych klas, dostosowanych do zadania, które chcemy zrealizować. Zaczniemy od załadowania modelu BERT base - jednego z najbardziej popularnych modeli, dla języka angielskiego. Za jego pomocą będziemy odgadywać brakujące wyrazy w tekście. Wykorzystamy do tego wywołanie `AutoModelForMaskedLM`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wTCDkZ1nKIEm"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForMaskedLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "abf19535a84b4c92a4c7e0135d5c090c",
            "ffff5a3d7eaa4ca687cc13ab89e30813",
            "d379e30e484a41a48a2c516962ad307d",
            "af871c5421db407da67d93050406328f",
            "c194d5b174464d40bcf37ae7dee9e4a9",
            "7ffbc008f7544a9491254a69d3b8fc12",
            "81ad72591d4c478489fbc8ffaba39304",
            "590025aa387f4eecb66db93a53897bf0",
            "4136dcc7013c4d54912d9bd97ae1f0de",
            "f5ed18dc6a3349219843ca03a60534c6",
            "b363b835d1ee49449e31a2f5fddf79d6",
            "3659c708cfb9428d8f0c952a83ff72e8",
            "224cbc723c11479098baeac5feedcdec",
            "1c8b66254b0a468f9f33ff8560be0a4e",
            "8424069986ae4d27a9facd634b1ae854",
            "c75a72c80a64449993b8dbcd5a8295e8",
            "7e09709759d14254b86b84732f4dbe6c",
            "26145f3ead7044168fd948a01bd5b7a4",
            "c1ed8971f41848278c37d1db09e9f54e",
            "fda33eb828614445a8d24e98225b63c7",
            "448f03c0c9f042c590b4f1e809d9c0eb",
            "dfbb7eeec75b46a1854d276d7509d96b"
          ]
        },
        "id": "BNO0HRQMOqVl",
        "outputId": "d0d1560d-59f0-433f-d58a-bb3a07ff19c4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abf19535a84b4c92a4c7e0135d5c090c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3659c708cfb9428d8f0c952a83ff72e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdgyGz752126"
      },
      "source": [
        "# Tokenizacja tekstu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmX8eu_mB9CO"
      },
      "source": [
        "Załadowanie samego modelu nie jest jednak wystarczające, żeby zacząć go wykorzystywać. Musimy mieć mechanizm zamiany tekstu (łańcucha znaków), na ciąg tokenów, należących do określonego słownika. W trakcie treningu modelu słownik ten jest określany (wybierany w sposób algorytmiczny) przed właściwym treningiem sieci neuronowej. Choć możliwe jest jego późniejsze rozszerzenie (douczenie na danych treningowych, pozwala również uzyskać reprezentację brakujących tokenów), to zwykle wykorzystuje się słownik w postaci, która została określona przed treningiem sieci neuronowej. Dlatego tak istotne jest wskazanie właściwego słownika dla tokenizera dokonującego podziału tekstu.\n",
        "\n",
        "Biblioteka posiada klasę `AutoTokenizer`, która akceptuje nazwę modelu, co pozwala automatycznie załadować słownik korespondujący z wybranym modelem sieci neuronowej. Trzeba jednak pamiętać, że jeśli używamy 2 modeli, to każdy z nich najpewniej będzie miał inny słownik, a co za tym idzie muszą one mieć własne instancje klasy `Tokenizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "8cd59c59e3c3413587fbae4c5eed5e9c",
            "3171b72013c644009cac1a4e1a8b6150",
            "c270f51e7f5744bc94785d8ae188fa50",
            "4d250e2c959f457a92473a1595417a1b",
            "fa6630df47904f028e19ed6385d56224",
            "f74467eee20a48d49fc492b9084031fe",
            "1508f4009a834d98958b7ffd68038be6",
            "b7806cd34d584a01834fa2fae02f2cdb",
            "dc2b3bfb36bf4244a9daae6674934a7e",
            "0ef406a1a5d840ad86f0fa9b1783623a",
            "a43771b2319c41179bc8a2b97b20965d",
            "c647df1993a7464d8b3bb8948120a5cd",
            "a985c99cd826494e993f2ec1bc9680ed",
            "195bab26775846a49e84eca1847c8787",
            "56a4a1fb6cf349a2a15cc6de7ff8afd1",
            "b8e0c159a16642c4abcef9c8210d828c",
            "b4f7c42122e342e5a48939865ad40388",
            "410b3e48854f4dddbe28cf70813d8b91",
            "46d710d20e0a4681847521a1600ce4c1",
            "d8add782325d46ffb8fdda6028887034",
            "4bcbab0a67804a749abc55792674c3e5",
            "40df73509ae34ed3b32689891821f165",
            "266167d902ef4366bd771c34f4d69b7b",
            "a5875a1062114606abd4de6e124f9b0d",
            "fa7b1a9da3bf4555b16a5a6a10d1a3f7",
            "076faefdcb634a9c868f2e64be0de7f0",
            "f1f892a8cb5b42f8bd840ea14c0e7a97",
            "d6d36fe088ef41709e0feb59b2cd091a",
            "a4e0a79c3b324f409bf27de76f8f67e8",
            "38c43d16278144138dbfd3dda93133ce",
            "1922a73502804ea0accb73306276ae3e",
            "3045316b459b4a19a3ec7b59419730d2",
            "0648d32f340641f69ab8101d54b26046"
          ]
        },
        "id": "PYUsVa1fBTPW",
        "outputId": "add56aa5-d8f0-417f-d32f-f30c2d995a58"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8cd59c59e3c3413587fbae4c5eed5e9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c647df1993a7464d8b3bb8948120a5cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "266167d902ef4366bd771c34f4d69b7b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXIePLylEFx2"
      },
      "source": [
        "Tokenizer posługuje się słownikiem o stałym rozmiarze. Podowuje to oczywiście, że nie wszystkie wyrazy występujące w tekście, będą się w nim znajdowały. Co więcej, jeśli użyjemy tokenizera do podziału tekstu w innym języku, niż ten dla którego został on stworzony, to taki tekst będzie dzielony na większą liczbę tokenów."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAGb1Jzhtr9p",
        "outputId": "9342a1df-ede5-4fc9-872a-d978cc438fc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,  1109,  3613,  3058, 17594, 15457,  1166,  1103, 16688,  3676,\n",
            "           119,   102]])\n",
            "torch.Size([1, 12])\n",
            "tensor([[  101,   163,  1161, 28259,  7774, 20671,  7128,   176, 28221, 28244,\n",
            "          1233, 28213,   179,  1161, 28257, 19339,   119,   102]])\n",
            "torch.Size([1, 18])\n"
          ]
        }
      ],
      "source": [
        "sentence1 = tokenizer.encode(\n",
        "    \"The quick brown fox jumps over the lazy dog.\", return_tensors=\"pt\"\n",
        ")\n",
        "print(sentence1)\n",
        "print(sentence1.shape)\n",
        "\n",
        "sentence2 = tokenizer.encode(\"Zażółć gęślą jaźń.\", return_tensors=\"pt\")\n",
        "print(sentence2)\n",
        "print(sentence2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ILQRogoErrt"
      },
      "source": [
        "Korzystająć z tokenizera dla języka angielsiego do podziału polskiego zdania, widzimy, że otrzymujemy znacznie większą liczbę tokenów. Żeby zobaczyć, w jaki sposób tokenizer dokonał podziału tekstu, możemy wykorzystać wywołanie `covert_ids_to_tokens`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOnw6mq81QFg",
        "outputId": "ed6eb325-e852-495a-c3d4-231ae055db35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]|The|quick|brown|fox|jumps|over|the|lazy|dog|.|[SEP]\n",
            "[CLS]|Z|##a|##ż|##ó|##ł|##ć|g|##ę|##ś|##l|##ą|j|##a|##ź|##ń|.|[SEP]\n"
          ]
        }
      ],
      "source": [
        "print(\"|\".join(tokenizer.convert_ids_to_tokens(list(sentence1[0]))))\n",
        "print(\"|\".join(tokenizer.convert_ids_to_tokens(list(sentence2[0]))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZzt3-w5GQDB"
      },
      "source": [
        "Widzimy, że dla jęzka angielskiego wszystkie wyrazy w zdaniu zostały przekształcone w pojedyncze tokeny. W przypadku zdania w języku polskim, zawierającego szereg znaków diakrytycznych sytuacja jest zupełnie inna - każdy znak został wyodrębniony do osobnego sub-tokenu. To, że mamy do czynienia z sub-tokenami sygnalizowane jest przez dwa krzyżyki poprzedzające dany sub-token. Oznaczają one, że ten sub-token musi być sklejony z porzedzającym go tokenem, aby uzyskać właściwy łańcuch znaków.\n",
        "\n",
        "## Zadanie 1 (1 punkt)\n",
        "\n",
        "Wykorzystaj tokenizer dla modelu `allegro/herbert-base-cased`, aby dokonać tokenizacji tych samych zdań. Jakie wnioski można wyciągnąć przyglądając się sposobowi tokenizacji za pomocą różnych słowników?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-20T13:58:00.312979Z",
          "start_time": "2022-12-20T13:58:00.303639Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEir3EhlHHaQ",
        "outputId": "12b075c5-9755-4bba-bad9-8796be884137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>|The</w>|qui|ck</w>|brow|n</w>|fo|x</w>|ju|mp|s</w>|o|ver</w>|the</w>|la|zy</w>|do|g</w>|.</w>|</s>\n",
            "<s>|Za|żół|ć</w>|gę|ślą</w>|ja|ź|ń</w>|.</w>|</s>\n"
          ]
        }
      ],
      "source": [
        "herbert_tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-base-cased\")\n",
        "\n",
        "sentence1 = herbert_tokenizer.encode(\n",
        "    \"The quick brown fox jumps over the lazy dog.\", \n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "sentence2 = herbert_tokenizer.encode(\n",
        "    \"Zażółć gęślą jaźń.\", \n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "print(\"|\".join(herbert_tokenizer.convert_ids_to_tokens(list(sentence1[0]))))\n",
        "print(\"|\".join(herbert_tokenizer.convert_ids_to_tokens(list(sentence2[0]))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US-hA9UMOPk_"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJquTQTDHLQY"
      },
      "source": [
        "W wynikach tokenizacji poza wyrazami/tokenami występującymi w oryginalnym tekście pojawiają się jeszcze dodatkowe znaczniki `[CLS]` oraz `[SEP]` (albo inne znaczniki - w zależności od użytego słownika). Mają one specjalne znaczenie i mogą być wykorzystywane do realizacji specyficznych funkcji związanych z analizą tekstu. Np. reprezentacja tokenu `[CLS]` wykorzystywana jest w zadaniach klasyfikacji zdań. Z kolei token `[SEP]` wykorzystywany jest do odróżnienia zdań, w zadaniach wymagających na wejściu dwóch zdań (np. określenia, na ile zdania te są podobne do siebie).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFR6OfWBU0TP"
      },
      "source": [
        "# Modelowanie języka"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2dVbEVuOoy1"
      },
      "source": [
        "Modele pretrenowane w reżimie self-supervised learning (SSL) nie posiadają specjalnych zdolności w zakresie rozwiązywania konkretnych zadań z zakresu przetwarzania języka naturalnego, takich jak odpowiadanie na pytania, czy klasyfikacja tekstu (z wyjątkiem bardzo dużych modeli, takich jak np. GPT-3). Można je jednak wykorzystać do określania prawdopodobieństwa wyrazów w tekście, a tym samym do sprawdzenia, jaką wiedzę posiada określony model w zakresie znajomości języka, czy też ogólną wiedzę o świecie. \n",
        "\n",
        "Aby sprawdzić jak model radzi sobie w tych zadaniach możemy dokonać inferencji na danych wejściowych, w których niektóre wyrazy zostaną zastąpione specjalnymi symbolami maskującymi, wykorzystywanymi w trakcie pre-treningu modelu. \n",
        "\n",
        "Należy mieć na uwadze, że różne modele mogą korzystać z różnych specjalnych sekwencji w trakcie pretreningu. Np. Bert korzysta z sekwencji `[MASK]`. Wygląd tokenu maskującego lub jego identyfikator możemy sprawdzić w [pliku konfiguracji tokenizera](https://huggingface.co/bert-base-cased/raw/main/tokenizer.json) dystrubowanym razem z modelem.\n",
        "\n",
        "W pierwszej kolejności, spróbujemy uzupełnić brakujący wyraz w angielskim zdaniu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgV2T4C3xsaD",
        "outputId": "5a728a04-3a23-4fce-c8b7-058a02bd2f7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]|The|quick|brown|[MASK]|jumps|over|the|lazy|dog|.|[SEP]\n",
            "tensor([-5.3489, -5.6063, -5.1303,  ..., -5.9625, -4.1559, -4.5403],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "sentence_en = tokenizer.encode(\n",
        "    \"The quick brown [MASK] jumps over the lazy dog.\", return_tensors=\"pt\"\n",
        ")\n",
        "print(\"|\".join(tokenizer.convert_ids_to_tokens(list(sentence_en[0]))))\n",
        "target = model(sentence_en)\n",
        "print(target.logits[0][4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc5CfCfSRV5E"
      },
      "source": [
        "Ponieważ zdanie po stokenizowaniu uzupełniane jest znacznikiem `[CLS]`, to zamaskowane słowo znajduje się na 4 pozycji. Wywołanie `target.logits[0][4]` pokazuje tensor z rozkładem prawdopodobieństwa poszczególnych wyrazów, które zostało określone na podstawie parametrów modelu. Możemy wybrać wyrazy, które posiadają największe prawdopodobieństwo, korzystając z wywołania `torch.topk`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3ugmBzhz5uu",
        "outputId": "26251d15-abf4-4d41-a8cb-e182bcf2b391"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.topk(\n",
              "values=tensor([12.1982, 11.2289, 10.6009, 10.1278, 10.0120], grad_fn=<TopkBackward0>),\n",
              "indices=tensor([ 3676,  1663,  5855,  4965, 21566]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "top = torch.topk(target.logits[0][4], 5)\n",
        "top"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz5nw1LbR5Va"
      },
      "source": [
        "Otrzymaliśmy dwa wektory - `values` zawierający składowe wektora wyjściowego sieci neuronowej (nieznormalizowane) oraz `indices` zawierający indeksy tych składowych. Na tej podstawie możemy wyświetlić wyraz, które według modelu są najbardziej prawdopodobnymi uzupełnieniami zamaskowanego wyrazu:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kkZKTw0J2BUn"
      },
      "outputs": [],
      "source": [
        "words = tokenizer.convert_ids_to_tokens(top.indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "kmDVEzZQ2Omz",
        "outputId": "a3592981-d01d-407d-a7de-f1efd3e5acc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 5 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.bar(words, top.values.detach().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "792etHKPSZrx"
      },
      "source": [
        "Zgodnie z oczekiwaniami, najbardziej prawdopodobnym uzupełnieniem brakującego wyrazu jest `dog`. Nieco zaskakujący może być drugi wyraz `##ie`, ale po dodaniu go do istniejącego tekstu otrzymamy zdanie: \"The quick brownie jumps over the lazy dog\", które również wydaje się sensowne (choć nieco zaskakujące)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QK7MybnTT-h"
      },
      "source": [
        "## Zadanie nr 2 (2 punkty)\n",
        "\n",
        "Wykorzystując model `allegro/herbert-base-cased` zaproponuj zdania z jednym brakującym wyrazem, weryfikujące zdolność tego modelu do:\n",
        "* uwzględniania polskich przypadków,\n",
        "* uwzględniania długodystansowych związków w tekście,\n",
        "* reprezentowania wiedzy o świecie.\n",
        "\n",
        "Dla każdego problemu wymyśl po 3 zdania sprawdzające i wyświetl predykcję dla 5 najbardziej prawdopodobnych wyrazów. \n",
        "\n",
        "Możesz wykorzystać kod z funkcji `plot_words`, który ułatwi Ci wyświetlanie wyników. Zweryfikuj również jaki token maskujący wykorzystywany jest w tym modelu. Pamiętaj również o załadowaniu modelu `allegro/herbert-base-cased`.\n",
        "\n",
        "Oceń zdolności modelu w zakresie wskazanych zadań."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-20T13:58:13.903939Z",
          "start_time": "2022-12-20T13:58:13.886635Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iy1RYqMvTKEe",
        "outputId": "58dacf89-0585-4371-e5b8-b76d1b8da6a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at allegro/herbert-base-cased were not used when initializing BertForMaskedLM: ['cls.sso.sso_relationship.bias', 'cls.sso.sso_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>|Grze|czne</w>|du|py</w>|nie</w>|chcą</w>|ze</w>|mną</w>|chodzić</w>|,</w>|nie|grze|czne</w>|du|py</w>|chcą</w>|się</w>|<mask>|</s>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>|Odwie|dziłem</w>|więc</w>|Włochy</w>|-</w>|krzy|wa</w>|wieża</w>|w</w>|<mask>|zrobiła</w>|na</w>|mnie</w>|kol|os|alne</w>|wrażenie</w>|</s>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>|Si|ad|łem</w>|przy</w>|<mask>|i</w>|dokoń|czyłem</w>|nowe</w>|laboratorium</w>|z</w>|PS|I</w>|</s>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def plot_words(sentence, word_model, word_tokenizer, mask=\"[MASK]\"):\n",
        "    sentence = word_tokenizer.encode(sentence, return_tensors=\"pt\")\n",
        "    tokens = word_tokenizer.convert_ids_to_tokens(list(sentence[0]))\n",
        "    print(\"|\".join(tokens))\n",
        "    target = word_model(sentence)\n",
        "    top = torch.topk(target.logits[0][tokens.index(mask)], 5)\n",
        "    words = word_tokenizer.convert_ids_to_tokens(top.indices)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.bar(words, top.values.detach().numpy())\n",
        "    plt.show()\n",
        "\n",
        "model_herbert = AutoModelForMaskedLM.from_pretrained(\"allegro/herbert-base-cased\")\n",
        "    \n",
        "sample_sentence1 = 'Grzeczne dupy nie chcą ze mną chodzić, niegrzeczne dupy chcą się <mask>'\n",
        "sample_sentence2 = 'Odwiedziłem więc Włochy - krzywa wieża w <mask> zrobiła na mnie kolosalne wrażenie'\n",
        "sample_sentence3 = 'Siadłem przy <mask> i dokończyłem nowe laboratorium z PSI'\n",
        "\n",
        "\n",
        "plot_words(sample_sentence1, model_allegro, allegro_tokenizer, '<mask>')\n",
        "plot_words(sample_sentence2, model_allegro, allegro_tokenizer, '<mask>')\n",
        "plot_words(sample_sentence3, model_allegro, allegro_tokenizer, '<mask>')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0D3wjqU5E7s"
      },
      "source": [
        "No z tą wiedzą o świecie to tak se jest - bo chciałem uzyskać tam krzywą wieżę w Pizie. Z polskimi przypadkami wydaje się git, a laby z PSI najlepiej robić przy stole, ale jak widać przy ognisku też da radę. Długodystansowe związki w tekście też tak sobie, chociaż trzeba przyznać że z perspektywy poprawności językowej to w każdym ze zdań wszystko było git."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe3jkYN4X0K6"
      },
      "source": [
        "# Klasyfikacja tekstu\n",
        "\n",
        "Pierwszym zadaniem, które zrealizujemy korzystając z modelu HerBERT będzie klasyfikacja tekstu. Będzie to jednak dość nietypowe zadanie. O ile oczekiwanym wynikiem jest klasyfikacja binarna, czyli dość popularny typ klasyfikacji, o tyle dane wejściowe są nietypowe, gdyż są to pary: `(pytanie, kontekst)`. Celem algorytmu jest określenie, czy na zadane pytanie można odpowiedzieć na podstawie informacji znajdujących się w kontekście.\n",
        "\n",
        "Model tego rodzaju jest nietypowy, ponieważ jest to zadanie z zakresu klasyfikacji par tekstów, ale my potraktujemy je jak zadanie klasyfikacji jednego tekstu, oznaczając jedynie fragmenty tekstu jako `Pytanie:` oraz `Kontekst:`. Wykorzystamy tutaj zdolność modeli transformacyjnych do automatycznego nauczenia się tego rodzaju znaczników, przez co proces przygotowania danych będzie bardzo uproszczony.\n",
        "\n",
        "Zbiorem danych, który wykorzystamy do treningu i ewaluacji modelu będzie PoQUAD - zbiór inspirowany angielskim [SQuADem](https://rajpurkar.github.io/SQuAD-explorer/), czyli zbiorem zawierającym ponad 100 tys. pytań i odpowiadających im odpowiedzi. Zbiór ten powstał niedawno i jest jeszcze rozbudowywany. Zawiera on pytania, odpowiedzi oraz konteksty, na podstawie których można udzielić odpowiedzi.\n",
        "\n",
        "W dalszej części laboratorium skoncentrujemy się na problemie odpowiadania na pytania."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJFq2RGgVArz"
      },
      "source": [
        "## Przygotowanie danych do klasyfikacji\n",
        "\n",
        "Przygotowanie danych rozpoczniemy od sklonowania repozytorium zawierającego pytania i odpowiedzi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASJlTuYmxnsO",
        "outputId": "f27dd83d-8f8f-4695-e384-c4b390bec57f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'poquad'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 33 (delta 13), reused 25 (delta 7), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ipipan/poquad.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IArBUss6j5L"
      },
      "source": [
        "Sprawdźmy jakie pliki znajdują się w katalogu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FrVu8eCxroj",
        "outputId": "6a66c75b-a427-42ee-b21f-311c73435919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "license.txt  poquad_dev.json  poquad_train.json  README.md\n"
          ]
        }
      ],
      "source": [
        "!ls poquad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu_APsiB6mLo"
      },
      "source": [
        "Możemy sprawadzić, co twórcy napisali na temat samego zbioru (niestety formatowanie tabel jest źle wyświetlane w Jupter notebooku):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "8c9Qq7sq6qfN",
        "outputId": "b89b7198-eaf4-44d3-d012-2f880fe53662"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# PoQuAD\n**PoQuAD** is the Polish Question Answering Dataset. It is modeled on the SQuAD 2.0, including the impossible questions. Additionally it includes a generative answer layer, which allows to train models to return the most natural sounding responses to the queries. The textual data are original Polish texts from Wikipedia, and they were selected to reflect the topics most relevant to Polish speakers.\n\n### The dataset consists of\n\n| Split | Size  |             |\n|-------|-------|-------------|\n| Train | 37414 |             |\n| Dev   | 4667  |             |\n| Test  | 4680  | (nonpublic) |\n| **Total** | **46761** |     |\n\n\n### Baseline Evaluation results\n\n#### Extractive QA\n\n**HERBERT-Large**\n| Metric      | Value  |\n|-------------|---------|\n| HasAns Exact Match | 64.27 |\n| HasAns F1          | 80.55 |\n| NoAns Exact Match  | 65.77 |\n| Total Exact Match  | 64.53 |\n| Total F1           | 77.96 |\n\n#### Generative QA\n\n**PLT5-Large**\n| Metric      | Value  |\n|-------------|---------|\n| HasAns Exact Match | 66.73 |\n| HasAns F1          | 80.84 |\n| NoAns Exact Match  | 52.13 |\n| Total Exact Match  | 64.17 |\n| Total F1           | 75.81 |\n\n### Citing\n\n```\n@misc{PoQuAD,\n  author = {{Ryszard Tuora, Natalia Zawadzka-Paluektau, Cezary Klamra, Aleksandra Zwierzchowska and Łukasz Kobyliński}},\n  title = {PoQuAD: Polish Question Answering Dataset},\n  year = {2022},\n  note = {Repository: https://github.com/ipipan/poquad},\n}\n```\n\n### Acknowledgments\nThis work was supported by the European Regional Development Fund as a part of the 2014-2020 Smart Growth Operational Programme: (1) Intelligent travel search system based on natural language understanding algorithms, project no. POIR.01.01.01-00-0798/19; (2) CLARIN - Common Language Resources and Technology Infrastructure, project no. POIR.04.02.00-00C002/19. The owner of the dataset is the Wrocław University of Science and Technology.\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display, Markdown, Latex\n",
        "\n",
        "with open(\"poquad/README.md\") as file:\n",
        "    display(Markdown(file.read()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxdjcmsD6yc6"
      },
      "source": [
        "Dane zbioru przechowywane są w plikach `poquad_train.json` oraz `poquad_dev.json`. Dostarczenie podziału na te grupy danych jest bardzo częstą praktyką w przypadku publicznych, dużych zbiorów danych, gdyż umożliwia porównywanie różnych modeli, korzystając z dokładnie takiego samego zestawu danych. Prawdopodobnie istnieje również zbiór `poquad_test.json`, który jednak nie jest udostępniany publicznie. Tak jest w przypadku SQuADu - twórcy zbioru automatycznie ewaluują dostarczane modele, ale nie udstoępniaja zbioru testowego. Dzięki temu trudniej jest nadmiernie dopasować model do danych testowych.\n",
        "\n",
        "Zobaczmy jaka jest struktura plików z danymi:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3ZLmxlzx4wd",
        "outputId": "41268ded-3174-457f-b700-42c14f0560a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"version\": \"2022-12-07 19:03:41.585976\",\n",
            "    \"data\": [\n",
            "        {\n",
            "            \"id\": 9773,\n",
            "            \"title\": \"Miszna\",\n",
            "            \"summary\": \"Miszna (hebr. ‏משנה‎ miszna „nauczać”, „ustnie przekazywać”, „studiować”, „badać”, od ‏שנה‎ szana „powtarzać”, „różnić się”, „być odmiennym”; jid. Miszne) – w judaizmie uporządkowany zbiór tekstów ustnego prawa uzupełniający Torę (Prawo pisane). Według wierzeń judaizmu stanowi ustną, niespisaną część prawa nadanego przez Boga na Synaju, tzw. Torę ustną. Jest świętym tekstem judaizmu i jest traktowana na równi z Tanach (Biblią hebrajską). Zbiór był w Izraelu od wieków przekazywany ustnie z pokolenia na pokolenie, zwiększył swój rozmiar szczególnie w okresie od III w. p.n.e. do II w. n.e. w wyniku systematycznego uzupełniania komentarzy przez tannaitów, żydowskich nauczycieli prawa ustnego. Miszna została spisana dopiero w II–III w. Prace redakcyjne zapoczątkował rabin Akiba ben Josef, a kształt ostatecznej redakcji tekstu nadał Juda ha-Nasi. Miszna składa się z 6 porządków (hebr.: sedarim), które dzielą się na 63 traktaty, te zaś na rozdziały i lekcje. Miszna jest częścią Talmudu i zawiera podstawowe reguły postępowania i normy prawne judaizmu.\",\n",
            "            \"url\": \"https://pl.wikipedia.org/wiki/Miszna\",\n",
            "            \"paragraphs\": [\n",
            "                {\n",
            "                    \"context\": \"Pisma rabiniczne – w tym Miszna – stanowią kompilację poglądów różnych rabinów na określony temat. Zgodnie z wierzeniami judaizmu Mojżesz otrzymał od Boga całą Torę, ale w dwóch częściach: jedną część w formie pisanej, a drugą część w formie ustnej. Miszna – jako Tora ustna – była traktowana nie tylko jako uzupełnienie Tory spisanej, ale również jako jej interpretacja i wyjaśnienie w konkretnych sytuacjach życiowych. Tym samym Miszna stanowiąca kodeks Prawa religijnego zaczęła równocześnie służyć za jego ustnie przekazywany podręcznik.\",\n",
            "                    \"qas\": [\n",
            "                        {\n",
            "                            \"question\": \"Czym są pisma rabiniczne?\",\n",
            "                            \"answers\": [\n",
            "                                {\n",
            "                                    \"text\": \"kompilację poglądów różnych rabinów na określony temat\",\n",
            "                                    \"answer_start\": 43,\n",
            "                                    \"answer_end\": 97,\n",
            "                                    \"generative_answer\": \"kompilacją poglądów różnych rabinów na określony temat\"\n",
            "                                }\n",
            "                            ],\n",
            "                            \"is_impossible\": false\n",
            "                        },\n",
            "                        {\n",
            "                            \"question\": \"Z ilu komponentów składała się Tora przekazana Mojżeszowi?\",\n",
            "                            \"answers\": [\n",
            "                                {\n",
            "                                    \"text\": \"dwóch\",\n",
            "                                    \"answer_start\": 172,\n"
          ]
        }
      ],
      "source": [
        "!head -30 poquad/poquad_dev.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjFnqM538V_9"
      },
      "source": [
        "Struktura pliku odpowiada strukturze danych w zbiorze SQuAD. Dane umieszczone są w kluczu `data` i podzielone na krotki odpowiadające pojedynczym artykułom Wikipedii. W ramach artykułu może być wybranych jeden lub więcej paragrafów, dla których w kluczu `qas` pojawiają się pytania (`question`), flaga `is_impossible`, wskazujace czy można odpowiedzieć na pytanie oraz odpowiedzi (o ile nie jest ustawiona flaga `is_impossible`). Odpowiedzi może być wiele i składają się one z treści odpowiedzi (`text`) traktowanej jako fragment kontekstu, a także naturalnej odpowiedzi na pytanie (`generative_answer`). \n",
        "\n",
        "Taki podział może wydawać się dziwny, ale zbiór skład zawiera tylko odpowiedzi pierwszego rodzaju. Wynika to z faktu, że w języku angielskim fragment tekstu będzie często stanowił dobrą odpowiedź na pytanie (oczywiście z wyjątkiem pytań dla których odpowiedź to `tak` lub `nie`).\n",
        "\n",
        "Natomiast ten drugi typ odpowiedzi jest szczególnie przydatny dla języka polskiego, ponieważ często odpowiedź chcemy syntaktycznie dostosować do pytania, co jest niemożliwe, jeśli odpowiedź wskazywana jest jako fragment kontekstu. \n",
        "W sytuacji, w której odpowiedzi były określane w sposób automatyczny, są one oznaczone jako `plausible_answers`.\n",
        "\n",
        "Zaczniemy od wczytania danych i wyświetlenia podstawowych statystyk dotyczących ilości artykułów oraz przypisanych do nich pytań."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDbf_9LKxuyJ",
        "outputId": "7766f02c-9816-4d36-a211-c3b4dd45250e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data articles: 7708\n",
            "Dev data articles: 964\n",
            "Train questions: 37417\n",
            "Dev questions: 4667\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open(\"poquad/poquad_train.json\") as input:\n",
        "    train_data = json.loads(input.read())[\"data\"]\n",
        "\n",
        "print(f\"Train data articles: {len(train_data)}\")\n",
        "\n",
        "with open(\"poquad/poquad_dev.json\") as input:\n",
        "    dev_data = json.loads(input.read())[\"data\"]\n",
        "\n",
        "print(f\"Dev data articles: {len(dev_data)}\")\n",
        "\n",
        "print(f\"Train questions: {sum([len(e['paragraphs'][0]['qas']) for e in train_data])}\")\n",
        "print(f\"Dev questions: {sum([len(e['paragraphs'][0]['qas']) for e in dev_data])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrLTRuCz-4nv"
      },
      "source": [
        "Ponieważ w pierwszym problemie chcemy stwierdzić, czy na pytanie można udzielić odpowiedzi na podstawie kontekstu, połączymy wszystkie kontekstu w jedną tablicę, aby móc losować z niej dane negatywne, gdyż liczba pytań nie posiadających odpowiedzi jest stosunkowo mała, co prowadziłoby utworzenia niezbalansowanego zbioru."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "c-1WgbVA1wsy"
      },
      "outputs": [],
      "source": [
        "all_contexts = [e[\"paragraphs\"][0][\"context\"] for e in train_data] + [\n",
        "    e[\"paragraphs\"][0][\"context\"] for e in dev_data\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Md-nxc7_jPy"
      },
      "source": [
        "W kolejnym kroku zamieniamy dane w formacie JSON na reprezentację zgodną z przyjętym założeniem.\n",
        "Chcemy by kontekst oraz pytanie występowały obok siebie i każdy z elementów był sygnalizowany wyrażeniem: `Pytanie:` i `Kontekst:`. Treść klasyfikowanego tekstu przyporządkowujemy do klucza `text`, natomiast klasę do klucza `label`, gdyż takie są oczekiwanie biblioteki Transformer.\n",
        "\n",
        "Pytania, które mają ustawiną flagę `is_impossible` na `True` trafiają wprost do przekształconego zbioru. Dla pytań, które posiadają odpowiedź, dodatkowo losowany jest jeden kontekst, który stanowi negatywny przykład. Weryfikujemy tylko, czy kontekst ten nie pokrywa się z kontekstem, który przypisany był do pytania. Nie przeprowadzamy bardziej zaawansowanych analiz, które pomogłyby wylkuczyć sytuację, w której inny kontekst również zawiera odpowiedź na pytanie, gdyż prawdopodobieństwo wylosowania takiego kontekstu jest bardzo małe.\n",
        "\n",
        "Na końcu wyświetlamy statystyki utworzonego zbioru danych."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbCkeE_f5Yg8",
        "outputId": "28dbb66f-4ba4-45ec-aa3d-3283f0d98479"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total count in train/dev: 68174/8520\n",
            "Positive count in train/dev: 30757/3853\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "\n",
        "tuples = [[], []]\n",
        "\n",
        "for idx, dataset in enumerate([train_data, dev_data]):\n",
        "    for data in dataset:\n",
        "        context = data[\"paragraphs\"][0][\"context\"]\n",
        "        for question_answers in data[\"paragraphs\"][0][\"qas\"]:\n",
        "            question = question_answers[\"question\"]\n",
        "            if question_answers[\"is_impossible\"]:\n",
        "                tuples[idx].append(\n",
        "                    {\n",
        "                        \"text\": f\"Pytanie: {question} Kontekst: {context} Czy kontekst zawiera pytanie?\",\n",
        "                        \"label\": 0,\n",
        "                    }\n",
        "                )\n",
        "            else:\n",
        "                tuples[idx].append(\n",
        "                    {\n",
        "                        \"text\": f\"Pytanie: {question} Kontekst: {context} Czy kontekst zawiera pytanie?\",\n",
        "                        \"label\": 1,\n",
        "                    }\n",
        "                )\n",
        "                while True:\n",
        "                    negative_context = random.choice(all_contexts)\n",
        "                    if negative_context != context:\n",
        "                        tuples[idx].append(\n",
        "                            {\n",
        "                                \"text\": f\"Pytanie: {question} Kontekst: {negative_context} Czy kontekst zawiera pytanie?\",\n",
        "                                \"label\": 0,\n",
        "                            }\n",
        "                        )\n",
        "                        break\n",
        "\n",
        "train_tuples, dev_tuples = tuples\n",
        "print(f\"Total count in train/dev: {len(train_tuples)}/{len(dev_tuples)}\")\n",
        "print(\n",
        "    f\"Positive count in train/dev: {sum([e['label'] for e in train_tuples])}/{sum([e['label'] for e in dev_tuples])}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2fQbatcAj5b"
      },
      "source": [
        "Widzimy, że uzyskane zbiory danych cechują się dość dobrym zbalansowaniem.\n",
        "\n",
        "Dobrą praktyką po wprowadzeniu zmian w zbiorze danych, jest wyświetlenie kilku przykładowych punktów danych, w celu wykrycia ewentualnych błędów, które powstały na etapie konwersji zbioru. Pozwala to uniknąć nieprzyjemnych niespodzianek, np. stworzenie identycznego zbioru danych testowych i treningowych."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr-oeLgR9H75",
        "outputId": "a029cda1-8b27-483a-ace8-56014b29ec25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'text': 'Pytanie: Co było powodem powrócenia konceptu porozumieniu monachijskiego? Kontekst: Projekty konfederacji zaczęły się załamywać 5 sierpnia 1942. Ponownie wróciła kwestia monachijska, co uaktywniło się wymianą listów Ripka – Stroński. Natomiast 17 sierpnia 1942 doszło do spotkania E. Beneša i J. Masaryka z jednej a Wł. Sikorskiego i E. Raczyńskiego z drugiej strony. Polscy dyplomaci zaproponowali podpisanie układu konfederacyjnego. W następnym miesiącu, tj. 24 września, strona polska przesłała na ręce J. Masaryka projekt deklaracji o przyszłej konfederacji obu państw. Strona czechosłowacka projekt przyjęła, lecz już w listopadzie 1942 E. Beneš podważył ideę konfederacji. W zamian zaproponowano zawarcie układu sojuszniczego z Polską na 20 lat (formalnie nastąpiło to 20 listopada 1942). Czy kontekst zawiera pytanie?', 'label': 1}]\n",
            "[{'text': 'Pytanie: Czym są pisma rabiniczne? Kontekst: Pisma rabiniczne – w tym Miszna – stanowią kompilację poglądów różnych rabinów na określony temat. Zgodnie z wierzeniami judaizmu Mojżesz otrzymał od Boga całą Torę, ale w dwóch częściach: jedną część w formie pisanej, a drugą część w formie ustnej. Miszna – jako Tora ustna – była traktowana nie tylko jako uzupełnienie Tory spisanej, ale również jako jej interpretacja i wyjaśnienie w konkretnych sytuacjach życiowych. Tym samym Miszna stanowiąca kodeks Prawa religijnego zaczęła równocześnie służyć za jego ustnie przekazywany podręcznik. Czy kontekst zawiera pytanie?', 'label': 1}]\n"
          ]
        }
      ],
      "source": [
        "print(train_tuples[0:1])\n",
        "print(dev_tuples[0:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTTry7LfBXKb"
      },
      "source": [
        "Ponieważ mamy nowe zbiory danych, możemy opakować je w klasy ułatwiające manipulowanie nimi. Ma to szczególne znaczenie w kontekście szybkiej tokenizacji tych danych, czy późniejszego szybkiego wczytywania wcześniej utworzonych zbiorów danych.\n",
        "\n",
        "W tym celu wykorzystamy bibliotekę `datasets`. Jej kluczowymi klasami są `Dataset` reprezentujący jeden z podzbiorów zbioru danych (np. podzbiór testowy) oraz `DatasetDict`, który łączy wszystkie podzbiory w jeden obiekt, którym możemy manipulować w całości. \n",
        "\n",
        "Dodatkowo zapiszemy tak utworzony zbiór danych na dysku. Jeśli później chcielibyśmy wykorzystać stworzony zbiór danych, to możemy to zrobić za pomocą komendy `load_dataset`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtTsPgmiDdG8"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "train_dataset = Dataset.from_list(train_tuples)\n",
        "dev_dataset = Dataset.from_list(dev_tuples)\n",
        "datasets = DatasetDict({\"train\": train_dataset, \"dev\": dev_dataset})\n",
        "datasets.save_to_disk(\"question-context-classification\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORcWOWjiCAhu"
      },
      "source": [
        "Dane tekstowe przed przekazaniem do modelu wmagają tokenizacji (co widzieliśmy już wcześniej). Efektywne wykonanie tokenizacji na całym zbiorze danych ułatwione jest przez obiekt `DatasetDict`. Definiujemy funkcję `tokenize_function`, która korzystając z załadowanego tokenizera, zamienia tekst na identyfikatory.\n",
        "\n",
        "W wywołaniu używamy opcji `padding` - uzupełniamy wszystkie teksty do długości najdłuszego tekstu. Dodatkowo, jeśli któryś tekst wykracza poza maksymalną długość obsługiwaną przez model, to jest on przycinany (`truncation=True`).\n",
        "\n",
        "Tokenizację aplikujemy do zbioru z wykorzystaniem przetwarzania batchowego (`batched=True`), które pozwala na szybsze stokenizowanie dużego zbioru danych."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLJSYvpFFlfO"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(examples):\n",
        "    return pl_tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "\n",
        "tokenized_datasets = datasets.map(tokenize_function, batched=True)\n",
        "tokenized_datasets[\"train\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5FJ54OLS0hK"
      },
      "source": [
        "Stokenizowane dane zawierają dodatkowe pola: `input_ids`, `token_type_ids` oraz `attention_mask`. Dla nas najważniejsze jest pole `input_ids`, które zawiera identyfikatory tokenów. Pozostałe dwa pola są ustawione na identyczne wartości (wszystkie tokeny mają ten sam typ, maska atencji zawiera wszystkie niezerowe tokeny), więc nie są one dla nas zbyt interesujące. Zobaczmy pola `text`, `input_ids` oraz `attention_mask` dla pierwszego przykładu:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgCExFTHSEYq"
      },
      "outputs": [],
      "source": [
        "example = tokenized_datasets[\"train\"][0]\n",
        "print(example[\"text\"])\n",
        "print(example[\"input_ids\"])\n",
        "print(example[\"attention_mask\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUiHWqsIUJvO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DL-RiReUT6e"
      },
      "source": [
        "Możemy sprawdzić, że liczba tokenów w polu `inut_ids`, które są różne od tokenu wypełnienia (`[PAD] = 1`) oraz maska atencji, mają tę samą długość:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeSZdD09T7TH"
      },
      "outputs": [],
      "source": [
        "print(len([e for e in example[\"input_ids\"] if e != 1]))\n",
        "print(len([e for e in example[\"attention_mask\"] if e == 1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKm4X7jzUjW7"
      },
      "source": [
        "Mając pewność, że przygotowane przez nas dane są prawidłowe, możemy przystąpić do procesu uczenia modelu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmVeK74JVPKz"
      },
      "source": [
        "## Trening z użyciem transformersów\n",
        "\n",
        "Biblioteka Transformes pozwala na załadowanie tego samego modelu dostosowanego do różnych zadań. Wcześniej używaliśmy modelu HerBERT do predykcji brakującego wyrazu. Teraz załadujemy ten sam model, ale z inną \"głową\". Zostanie użyta warstwa, która pozwala na klasyfikację całego tekstu do jednej z n-klas. Wystarczy podmienić klasę, za pomocą której ładujemy model na `AutoModelForSequenceClassification`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVs4tK1WHUT8"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"allegro/herbert-base-cased\", num_labels=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axdrBfSuE5YO"
      },
      "source": [
        "Komunikat diagnostyczny, który pojawia się przy ładowaniu modelu jest zgodny z naszymi oczekiwaniami. Model HerBERT był trenowany do predykcji tokenów, a nie klasyfikacji tekstu. Dlatego też ostatnia warstwa (`classifier.weight` oraz `classifier.bias`) jest inicjowana losowo. Wagi zostaną ustalone w trakcie procesu fine-tuningu modelu.\n",
        "\n",
        "Korzystanie z biblioteki Transformers uwalnia nas od manualnego definiowania pętli uczącej, czy wywoływania algorytmu wstecznej propagacji błędu. Trening realizowany jest z wykorzystaniem klasy `Trainer`  (i jej specjlizacji). Argumenty treningu określane są natomiast w klasie `TrainingArguments`.  Klasy te są [bardzo dobrze udokumentowane](https://huggingface.co/docs/transformers/main_classes/trainer#trainer), więc nie będziemy omawiać wszystkich możliwych opcji.\n",
        "\n",
        "Najważniejsze opcje są następujące:\n",
        "* output_dir - katalog do którego zapisujemy wyniki,\n",
        "* do_train - wymagamy aby przeprowadzony był trening,\n",
        "* do_eval - wymagamy aby przeprowadzona była ewaluacja modelu,\n",
        "* evaluation_strategy - określenie momentu, w którym realizowana jest ewaluacja,\n",
        "* evaluation_steps - określenie co ile kroków (krok = przetworzenie 1 batcha) ma być realizowana ewaluacja,\n",
        "* per_device_train/evaluation_batch_size - rozmiar batcha w trakcie treningu/ewaluacji,\n",
        "* learning_rate - szybkość uczenia, \n",
        "* num_train_epochs - liczba epok uczenia,\n",
        "* logging... - parametry logowania postępów uczenia,\n",
        "* save_strategy - jak często należy zapisywać wytrenowany model,\n",
        "* fp16 - użycie arytmetyki o zmniejszonej dokładności, przyspieszającej proces uczenia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iub6XtjPH7O6"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "import numpy as np\n",
        "\n",
        "arguments = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=400,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=5e-05,\n",
        "    num_train_epochs=1,\n",
        "    logging_first_step=True,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=50,\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlShURnsVAXC"
      },
      "source": [
        "W trakcie treningu będziemy chcieli zobaczyć, czy model poprawnie radzi sobie z postawionym mu problemem. Najlepszym sposobem na podglądanie tego procesu jest obserwowanie wykresów. Model może raportować szereg metryk, ale najważniejsze dla nas będą następujące wartości:\n",
        "* wartość funkcji straty na danych treningowych - jeślie nie spada w trakcie uczenia, znaczy to, że nasz model nie jest poprawnie skonstruowany lub dane uczące są niepoprawne,\n",
        "* wartość jednej lub wielu metryk uzyskiwanych na zbiorze walidacyjnym - możemy śledzić wartość funkcji straty na zbiorze ewaluacyjnym, ale warto również wyświetlać metryki, które da się łatwiej zinterpretować; dla klasyfikacji zbalansowanego zbioru danych może to być dokładność (`accuracy`).\n",
        "\n",
        "Biblioteka Transformers pozwala w zasadzie na wykorzystanie dowolnej metryki, ale szczególnie dobrze współpracuje z metrykami zdefiniowanymi w bibliotece `evaluate` (również autorstwa Huggingface). \n",
        "\n",
        "Wykorzystanie metryki wymaga od nas zdefiniowania metody, która akceptuje batch danych, który zawieraja predykcje (wektory zwrócone na wyjściu modelu) oraz referencyjne wartości - wartości przechowywane w kluczu `label`. Przed obliczeniem metryki konieczne jest \"odcyfrowanie\" zwróconych wartości. W przypadku klasyfikacji oznacza to po prostu wybranie najbardziej prawodopodobnej klasy i porównanie jej z klasą referencyjną.\n",
        "\n",
        "Użycie konkretnej metryki realizowane jest za pomocą wywołania `metric.compute`, która akceptuje predykcje (`predictions`) oraz wartości referencyjne (`references`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S861cZksGrWM"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1qk791L6_I7"
      },
      "source": [
        "Ostatnim krokiem w procesie treningu jest stworzenie obiektu klasy `Trainer`. Akceptuje ona m.in. model, który wykorzystywany jest w treningu, przygotowane argumenty treningu, zbiory do treningu, ewaluacji, czy testowania oraz wcześniej określoną metodę do obliczania metryki na danych ewaluacyjnych.\n",
        "\n",
        "W przetwarzaniu jezyka naturalnego dominującym podejściem jest obecnie rozdzielenie procesu treningu na dwa etapy: pre-treining oraz fine-tuning. W pierwszym etapie model trenowany jest w reżimie self-supervised learning (SSL). Wybierane jest zadanie związane najczęściej z modelowaniem języka - może to być kauzalne lub maskowane modelowanie języka. \n",
        "\n",
        "W *kauzalnym modelowaniu języka* model językowy, na podstawie poprzedzających wyrazów określa prawdopodobieństwo wystąpienia kolejnego wyrazu. W *maskowanym modelowaniu języka* model językowy odgaduje w tekście część wyrazów, która została z niego usunięta.\n",
        "\n",
        "W obu przypadkach dane, na których trenowany jest model nie wymagają ręcznego oznakowania (tagowaina). Wystarczy jedynie posiadać duży korpus danych językowych, aby wytrenować model, który dobrze radzi sobie z jednym z tych zadań. Model tego rodzaju był pokazany na początku laboratorium.\n",
        "\n",
        "W drugim etapie - fine-tuningu (dostrajaniu modelu) - następuje modyfikacja parametrów modelu, w celu rozwiązania konkretnego zadania. W naszym przypadku pierwszym zadaniem tego rodzaju jest klasyfikacja. Dostroimy zatem model `herbert-base-cased` do zadania klasyfikacji par: pytanie - kontekst.\n",
        "\n",
        "Wykorzystamy wcześniej utworzone zbiory danych i dodatkowo zmienimy kolejność danych, tak aby uniknąć potencjalnego problemu z korelacją danych w ramach batcha. Wykorzystujemy do tego wywołanie `shuffle`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSM6Qmv_WUgz"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=arguments,\n",
        "    train_dataset=tokenized_datasets[\"train\"].shuffle(seed=42),\n",
        "    eval_dataset=tokenized_datasets[\"dev\"].shuffle(seed=42),\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx8WSdqx9Hv5"
      },
      "source": [
        "Zanim uruchomimy trening, załadujemy jeszcze moduł TensorBoard. Nie jest to krok niezbędy. TensorBoard to biblioteka, która pozwala na wyświetlanie w trakcie procesu trening wartości, które wskazują nam, czy model trenuje się poprawnie. W naszym przypadku będzie to `loss` na danych treningowych, `loss` na danych ewaluacyjnych oraz wartość metryki `accuracy`, którą zdefiniowaliśmy wcześniej. Wywołanie tej komórki na początku nie da żadnego efektu, ale można ją odświeżać, za pomocą ikony w menu TensorBoard (ewentualnie włączyć automatyczne odświeżanie). Wtedy w miarę upływu treningu będziemy mieli podgląd, na przebieg procesu oraz osiągane wartości interesujących nas parametrów.\n",
        "\n",
        "Warto zauważyć, że istenieje szereg innych narzędzi do monitorowania eksperymentów z treningiem sieci. Wśród nich dużą popularnością cieszą się [WanDB](https://wandb.ai/site) oraz [Neptune.AI](https://neptune.ai/). Ich zaletą jest m.in. to, że możemy łatwo archiwizować przeprowadzone eksperymenty, porównywać je ze sobą, analizować wpływ hiperparametrów na uzyskane wyniki, itp."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUCeNC4X1bJT"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output/runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5d5E2OO-P5C"
      },
      "source": [
        "Uruchomienie procesu treningu jest już bardzo proste, po tym jak przygotowaliśmy wszystkie niezbędne szczegóły. Wystarczy wywołać metodę `trainer.train()`. Warto mieć na uwadze, że proces ten będzie jednak długotrwały - jedna epoka treningu na przygotowanych danych będzie trwała ponad 1 godzinę. Na szczęście, dzięki ustawieniu ewaluacji co 400 kroków, będziemy mogli obserwować jak model radzie sobie z postawionym przed nim problemem na danych ewaluacyjnych."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sULHvH_bMBmW"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kmxKtZp_VP6"
      },
      "source": [
        "## Zadanie 3 (1 punkt)\n",
        "\n",
        "Zinterpretuj wyniki uzyskane przy treningu modelu klasyfikacyjnego."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJXK8qWCtoY-"
      },
      "source": [
        "# Odpowiadanie na pytania\n",
        "\n",
        "Drugim problemem, którym zajmie się w tym laboratorium jest odpowiadanie na pytania. Zmierzymy się z wariantem tego problemu, w którym model sam formułuje odpowiedź, na podstawie pytania i kontekstu, w których znajduje się odpowiedź na pytanie (w przeciwieństwie do wariantu, w którym model wskazuje lokalizację odpowiedzi na pytanie)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL3VibwXYdu2"
      },
      "source": [
        "\n",
        "## Zadanie 4 (1 punkt)\n",
        "\n",
        "Rozpocznij od przygotowania danych. Wybierzem tylko te pytania, które posiadają odpowiedź (`is_impossible=False`). Uwzględnij zarówno pytania *pewne* (pole `answers`) jak i *prawdopodobne* (pole `plausible_answers`). Wynikowy zbiór danych powinien mieć identyczną strukturę, jak w przypadku zadania z klasyfikacją, ale etykiety zamiast wartości 0 i 1, powinny zawierać odpowiedź na pytanie, a sama nazwa etykiety powinna być zmieniona z `label` na `labels`, w celu odzwierciedlenia faktu, że teraz zwracane jest wiele etykiet.\n",
        "\n",
        "Wyświetl liczbę danych (par: pytanie - odpowiedź) w zbiorze treningowym i zbiorze ewaluacyjnym.\n",
        "\n",
        "Opakuj również zbiory w klasy z biblioteki `datasets` i zapisz je na dysku."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auGRaK7x1vf9"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "\n",
        "tuples = [[], []]\n",
        "\n",
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsZe71D5FMhw"
      },
      "source": [
        "Zanim przejdziemy do dalszej części, sprawdźmy, czy dane zostały poprawnie utworzone. Zweryfikujmy przede wszystkim, czy klucze `text` oraz `label` zawieraja odpowiednie wartości:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZN8Q0h7PF_aw"
      },
      "outputs": [],
      "source": [
        "print(datasets[\"train\"][0][\"text\"])\n",
        "print(datasets[\"train\"][0][\"labels\"])\n",
        "print(datasets[\"dev\"][0][\"text\"])\n",
        "print(datasets[\"dev\"][0][\"labels\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLghVU7EEaHb"
      },
      "source": [
        "Tokenizacja danych dla problemu odpowiadania na pytania jest nieco bardziej problematyczna. W pierwszej kolejności trzeba wziąć pod uwagę, że dane wynikowe (etykiety), też muszą podlegać tokenizacji. Realizowane jest to poprzez wywołanie tokenizera, z opcją `text_target` ustawioną na łańcuch, który ma być stokenizowany.\n",
        "\n",
        "Ponadto wcześniej nie przejmowaliśmy się za bardzo tym, czy wykorzystywany model obsługuje teksty o założonej długości. Teraz jednak ma to duże znaczenie. Jeśli użyjemy modelu, który nie jest w stanie wygenerować odpowiedzi o oczekiwanej długości, to nie możemy oczekiwać, że model ten będzie dawał dobre rezultaty dla danych w zbiorze treningowym i testowym.\n",
        "\n",
        "W pierwszej kolejności dokonamy więc tokenizacji bez ograniczeń co do długości tekstu. Ponadto, stokenizowane odpowiedzi przypiszemy do klucza `label`. Do tokenizacji użyjemy tokenizera stowarzyszonego z modelem ~`google/mt5-small`~ `allegro/plt5-base`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-22T10:30:09.564553Z",
          "start_time": "2022-12-22T10:30:09.155839Z"
        },
        "id": "WljAN9tMg5uU"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"allegro/plt5-base\")\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    model_inputs = tokenizer(examples[\"text\"])\n",
        "    labels = tokenizer(text_target=examples[\"labels\"])\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "# tokenized_datasets = datasets.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlSHE98SIFjv"
      },
      "source": [
        "Sprawdźmy jak dane wyglądają po tokenizacji:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3IM-Cd1IEba"
      },
      "outputs": [],
      "source": [
        "print(tokenized_datasets[\"train\"][0].keys())\n",
        "print(tokenized_datasets[\"train\"][0][\"input_ids\"])\n",
        "print(tokenized_datasets[\"train\"][0][\"labels\"])\n",
        "print(len(tokenized_datasets[\"train\"][0][\"input_ids\"]))\n",
        "print(len(tokenized_datasets[\"train\"][0][\"labels\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seBM6iumIY8x"
      },
      "source": [
        "Wykorzystywany przez nas model obsługuje teksty od długości do 512 sub-tokenów. Konieczne jest zatem sprawdzenie, czy w naszych danych nie ma tekstów od większej długości.\n",
        "\n",
        "## Zadanie 5 (1 punkt)\n",
        "\n",
        "Stwórz histogramy prezentujące rozkład długości tekstów wejściowych (`input_ids`) oraz odpowiedzi (`label`) dla zbioru treningowego. Zinterpretuj otrzymane wyniki."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSg4cZ2Xw9fJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTTrGUuvQQ63"
      },
      "source": [
        "Ponieważ nasz model obsługuje tylko teksty do długości 512 znaków, a większość odpowiedzi jest znacznie krótsza niż maksymalna długość, ograniczmy je do długości 32. \n",
        "\n",
        "W poniższym kodzie uwzględniamy również fakt, że przy obliczaniu funkcji straty nie interesuje nas wliczanie tokenów wypełnienia (PAD), gdyż ich udział byłby bardzo duży, a nie wpływają one w żaden pozytywny sposób na ocenę poprawności działania modelu.\n",
        "\n",
        "Konteksty ograniczamy do 256 tokenów, ze wzgędu na ograniczenia pamięciowe (zajętość pamięci dla modelu jest proporcjonalna do kwadratu długości tekstu)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpW4MNa1tGUV"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    result = tokenizer(examples[\"text\"], truncation=True, max_length=256)\n",
        "    targets = tokenizer(\n",
        "        examples[\"labels\"], truncation=True, max_length=32, padding=True\n",
        "    )\n",
        "    input_ids = [\n",
        "        [(l if l != tokenizer.pad_token_id else -100) for l in e]\n",
        "        for e in targets[\"input_ids\"]\n",
        "    ]\n",
        "    result[\"labels\"] = input_ids\n",
        "    return result\n",
        "\n",
        "\n",
        "tokenized_datasets = datasets.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCLIl_cIyRxH"
      },
      "source": [
        "Następnie weryfkiujemy, czy przetworzone teksty mają poprawną postać."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQ9i4ApASNIL"
      },
      "outputs": [],
      "source": [
        "print(tokenized_datasets[\"train\"][0].keys())\n",
        "print(tokenized_datasets[\"train\"][0][\"input_ids\"])\n",
        "print(tokenized_datasets[\"train\"][0][\"labels\"])\n",
        "print(len(tokenized_datasets[\"train\"][0][\"input_ids\"]))\n",
        "print(len(tokenized_datasets[\"train\"][0][\"labels\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEqhSrxLAwCH"
      },
      "source": [
        "Dla problemu odpowiadania na pytania potrzebować będziemy innego pre-trenowanego modelu oraz innego przygotowania danych. Jako model bazowy wykrzystamy ~wielojęzyczny~ polski wariant modelu T5 - ~[mT5](https://huggingface.co/google/mt5-base)~ [plT5](https://huggingface.co/allegro/plt5-base). Model ten trenowany był w zadaniu *span corruption*, czyli zadani polegającym na usunięciu fragmentu tekstu. Model na wejściu otrzymywał tekst z pominiętymi pewnymi fragmentami, a na wyjściu miał odtwarzać te fragmenty. Oryginalny model T5 dodatkowo pretrenowany był na kilku konkretnych zadaniach z zakresu NLP (w tym odpowiadaniu na pytania). W wariancie ~mT5~ plT5 nie przeprowadzono jednak takiego dodatkowego procesu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvEOsWlAiWOu"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"allegro/plt5-base\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UhNiDor4CSa"
      },
      "source": [
        "## Trening modelu QA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TWCljD_yb0E"
      },
      "source": [
        "Ostatnim krokiem przed uruchomieniem treningu jest zdefiniowanie metryk, wskazujacych jak model radzi sobie z problemem. Wykorzystamy dwie metryki:\n",
        "* *exact match* - która sprawdza dokładne dopasowanie odpowiedzi do wartości referencyjnej, metryka ta jest bardzo restrykcyjna, ponieważ pojedynczy znak będzie powodował, że wartość będzie niepoprawna,\n",
        "* *blue score* - metryka uwzględniająca częściowe dopasowanie pomiędzy odpowiedzią a wartością referencyjną, najczęściej używana jest do oceny maszynowego tłumaczenia tekstu, ale może być również przydatna w ocenie wszelkich zadań, w których generowany jest tekst.\n",
        "\n",
        "Wykorzystujemy bibilotekę `evaluate`, która zawiera definicje obu metryk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcjDjmjT2rVm"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "exact = evaluate.load(\"exact_match\")\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    print(decoded_preds[0])\n",
        "    print(decoded_labels[0])\n",
        "\n",
        "    result = exact.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\n",
        "        **result,\n",
        "        **bleu.compute(predictions=decoded_preds, references=decoded_labels),\n",
        "    }\n",
        "\n",
        "    prediction_lens = [\n",
        "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions\n",
        "    ]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_49SDmpy5yo"
      },
      "source": [
        "## Zadanie 7 (1 punkty)\n",
        "\n",
        "Korzystając z klasy Seq2SeqTrainingArguments zdefiniuj następujące parametry trenignu:\n",
        "* liczba epok: ~1~ 3\n",
        "* wielkość paczki: 16\n",
        "* ewaluacja co 100 kroków,\n",
        "* szybkość uczenia: ~5e-05~ 1e-4\n",
        "* optymalizator: adafactor\n",
        "* maksymalna długość generowanej odpowiedzi: 32,\n",
        "* akumulacja wyników ewaluacji: 4\n",
        "* generowanie wyników podczas ewaluacji\n",
        "\n",
        "Argumenty powinny również wskazywać, że przeprowadzoany jest proces uczenia i ewaluacji."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4fTGCQ5yWc-"
      },
      "outputs": [],
      "source": [
        "# your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1wc95I3zrEC"
      },
      "source": [
        "## Zadanie 8 (1 punkt)\n",
        "\n",
        "Utwórz obiekt trenujący `Seq2SeqTrainer`, za pomocą którego będzie trenowany model odpowiadający na pytania. \n",
        "\n",
        "Obiekt ten powinien:\n",
        "* wykorzystywać model ~`mt5-base`~ `allegro/plt5-base`,\n",
        "* wykorzystywać zbiór `train` do treningu,\n",
        "* wykorzystawać zbiór `dev` do evaluacji,\n",
        "* wykorzystać klasę batchującą (`data_collator`) o nazwie `DataCollatorWithPadding`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-20T14:05:20.769322Z",
          "start_time": "2022-12-20T14:05:20.344307Z"
        },
        "id": "X-l-Phk6zkvL"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "\n",
        "# your code goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6nAWvNc0qbT"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output_qa/runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pyrQ4m70WE6"
      },
      "source": [
        "Mając przygotowane wszystkie dane wejściowe możemy rozpocząć proces treningu. \n",
        "\n",
        "**Uwaga**: proces treningu na Google Colab z wykorzystaniem akceleratora zajmuje ok 3 godziny. Uruchomienie treningu na CPU może trwać ponad 1 dzień!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVew4vRlhyVP"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkdm725n8TRR"
      },
      "source": [
        "Porównaj otrzymane wyniki z wynikami zaprezentowanymi na [karcie modelu plT5-base](https://huggingface.co/azwierzc/plt5-base-poquad) trenowanego na tym zbiorze danych."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3-k_ctqvwmf"
      },
      "source": [
        "## Zadanie 9 (1 punkt)\n",
        "\n",
        "Korzystając z wywołania `predict` w klasie `trainer` wygeneruj odpowiedzi dla 10 losowo wybranych pytań ze zbioru ewaluacyjnego."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS0uK6gM8TRR"
      },
      "source": [
        "# Pytania kontrolne (1 punkt)\n",
        "\n",
        "1. W jaki sposób modele neuronalne rozwiązały problem polegajacy na tym, że w językach naturalnych zbiór wyrazów jest nieograniczony, a sieć neuronowa może przetwarzać wyłącznie dane kategoryczne, posiadające skończoną liczbę wartości?\n",
        "\n",
        "2. Czy możliwe jest wykorzystanie tego samego tokenizera, dla różnych sieci neuronowych przetwarzających dane tekstowe?\n",
        "\n",
        "3. Czym różni się model HerBERT odgadujący zamaskowane wyrazy od modelu zdolnego do klasyfikacji tekstu?\n",
        "\n",
        "4. Jaki problem występuje z metryką \"exact match\" jeśli model ma za zadanie generowanie tekstu?\n",
        "\n",
        "5. Przedstaw przynajmniej jedną zaletę oraz jedną wadę modeli neuronalnych w kontekście przetwarzania tekstu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kupQW0A38TRR"
      },
      "source": [
        "# Zadanie dodatkowe (2 punkty)\n",
        "\n",
        "Dla każdego z trenowanych modeli (modelu klasyfikacyjnego oraz modelu generującego tekst) zmodyfikuj przynajmniej po 3 hiperparametry i dla każdej modyfikacji przeprowadź ponowny trening (łącznie min. 6 treningów).\n",
        "\n",
        "Zinterpretuj otrzymane wyniki."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxi5nQER8TRR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": false,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "abf19535a84b4c92a4c7e0135d5c090c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffff5a3d7eaa4ca687cc13ab89e30813",
              "IPY_MODEL_d379e30e484a41a48a2c516962ad307d",
              "IPY_MODEL_af871c5421db407da67d93050406328f"
            ],
            "layout": "IPY_MODEL_c194d5b174464d40bcf37ae7dee9e4a9"
          }
        },
        "ffff5a3d7eaa4ca687cc13ab89e30813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ffbc008f7544a9491254a69d3b8fc12",
            "placeholder": "​",
            "style": "IPY_MODEL_81ad72591d4c478489fbc8ffaba39304",
            "value": "Downloading: 100%"
          }
        },
        "d379e30e484a41a48a2c516962ad307d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_590025aa387f4eecb66db93a53897bf0",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4136dcc7013c4d54912d9bd97ae1f0de",
            "value": 570
          }
        },
        "af871c5421db407da67d93050406328f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5ed18dc6a3349219843ca03a60534c6",
            "placeholder": "​",
            "style": "IPY_MODEL_b363b835d1ee49449e31a2f5fddf79d6",
            "value": " 570/570 [00:00&lt;00:00, 19.1kB/s]"
          }
        },
        "c194d5b174464d40bcf37ae7dee9e4a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ffbc008f7544a9491254a69d3b8fc12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81ad72591d4c478489fbc8ffaba39304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "590025aa387f4eecb66db93a53897bf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4136dcc7013c4d54912d9bd97ae1f0de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5ed18dc6a3349219843ca03a60534c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b363b835d1ee49449e31a2f5fddf79d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3659c708cfb9428d8f0c952a83ff72e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_224cbc723c11479098baeac5feedcdec",
              "IPY_MODEL_1c8b66254b0a468f9f33ff8560be0a4e",
              "IPY_MODEL_8424069986ae4d27a9facd634b1ae854"
            ],
            "layout": "IPY_MODEL_c75a72c80a64449993b8dbcd5a8295e8"
          }
        },
        "224cbc723c11479098baeac5feedcdec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e09709759d14254b86b84732f4dbe6c",
            "placeholder": "​",
            "style": "IPY_MODEL_26145f3ead7044168fd948a01bd5b7a4",
            "value": "Downloading: 100%"
          }
        },
        "1c8b66254b0a468f9f33ff8560be0a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1ed8971f41848278c37d1db09e9f54e",
            "max": 435779157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fda33eb828614445a8d24e98225b63c7",
            "value": 435779157
          }
        },
        "8424069986ae4d27a9facd634b1ae854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_448f03c0c9f042c590b4f1e809d9c0eb",
            "placeholder": "​",
            "style": "IPY_MODEL_dfbb7eeec75b46a1854d276d7509d96b",
            "value": " 436M/436M [00:06&lt;00:00, 71.5MB/s]"
          }
        },
        "c75a72c80a64449993b8dbcd5a8295e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e09709759d14254b86b84732f4dbe6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26145f3ead7044168fd948a01bd5b7a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1ed8971f41848278c37d1db09e9f54e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fda33eb828614445a8d24e98225b63c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "448f03c0c9f042c590b4f1e809d9c0eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfbb7eeec75b46a1854d276d7509d96b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cd59c59e3c3413587fbae4c5eed5e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3171b72013c644009cac1a4e1a8b6150",
              "IPY_MODEL_c270f51e7f5744bc94785d8ae188fa50",
              "IPY_MODEL_4d250e2c959f457a92473a1595417a1b"
            ],
            "layout": "IPY_MODEL_fa6630df47904f028e19ed6385d56224"
          }
        },
        "3171b72013c644009cac1a4e1a8b6150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f74467eee20a48d49fc492b9084031fe",
            "placeholder": "​",
            "style": "IPY_MODEL_1508f4009a834d98958b7ffd68038be6",
            "value": "Downloading: 100%"
          }
        },
        "c270f51e7f5744bc94785d8ae188fa50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7806cd34d584a01834fa2fae02f2cdb",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc2b3bfb36bf4244a9daae6674934a7e",
            "value": 29
          }
        },
        "4d250e2c959f457a92473a1595417a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ef406a1a5d840ad86f0fa9b1783623a",
            "placeholder": "​",
            "style": "IPY_MODEL_a43771b2319c41179bc8a2b97b20965d",
            "value": " 29.0/29.0 [00:00&lt;00:00, 1.49kB/s]"
          }
        },
        "fa6630df47904f028e19ed6385d56224": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f74467eee20a48d49fc492b9084031fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1508f4009a834d98958b7ffd68038be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7806cd34d584a01834fa2fae02f2cdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc2b3bfb36bf4244a9daae6674934a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ef406a1a5d840ad86f0fa9b1783623a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a43771b2319c41179bc8a2b97b20965d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c647df1993a7464d8b3bb8948120a5cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a985c99cd826494e993f2ec1bc9680ed",
              "IPY_MODEL_195bab26775846a49e84eca1847c8787",
              "IPY_MODEL_56a4a1fb6cf349a2a15cc6de7ff8afd1"
            ],
            "layout": "IPY_MODEL_b8e0c159a16642c4abcef9c8210d828c"
          }
        },
        "a985c99cd826494e993f2ec1bc9680ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4f7c42122e342e5a48939865ad40388",
            "placeholder": "​",
            "style": "IPY_MODEL_410b3e48854f4dddbe28cf70813d8b91",
            "value": "Downloading: 100%"
          }
        },
        "195bab26775846a49e84eca1847c8787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46d710d20e0a4681847521a1600ce4c1",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8add782325d46ffb8fdda6028887034",
            "value": 213450
          }
        },
        "56a4a1fb6cf349a2a15cc6de7ff8afd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bcbab0a67804a749abc55792674c3e5",
            "placeholder": "​",
            "style": "IPY_MODEL_40df73509ae34ed3b32689891821f165",
            "value": " 213k/213k [00:00&lt;00:00, 640kB/s]"
          }
        },
        "b8e0c159a16642c4abcef9c8210d828c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4f7c42122e342e5a48939865ad40388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "410b3e48854f4dddbe28cf70813d8b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46d710d20e0a4681847521a1600ce4c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8add782325d46ffb8fdda6028887034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4bcbab0a67804a749abc55792674c3e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40df73509ae34ed3b32689891821f165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "266167d902ef4366bd771c34f4d69b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5875a1062114606abd4de6e124f9b0d",
              "IPY_MODEL_fa7b1a9da3bf4555b16a5a6a10d1a3f7",
              "IPY_MODEL_076faefdcb634a9c868f2e64be0de7f0"
            ],
            "layout": "IPY_MODEL_f1f892a8cb5b42f8bd840ea14c0e7a97"
          }
        },
        "a5875a1062114606abd4de6e124f9b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6d36fe088ef41709e0feb59b2cd091a",
            "placeholder": "​",
            "style": "IPY_MODEL_a4e0a79c3b324f409bf27de76f8f67e8",
            "value": "Downloading: 100%"
          }
        },
        "fa7b1a9da3bf4555b16a5a6a10d1a3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38c43d16278144138dbfd3dda93133ce",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1922a73502804ea0accb73306276ae3e",
            "value": 435797
          }
        },
        "076faefdcb634a9c868f2e64be0de7f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3045316b459b4a19a3ec7b59419730d2",
            "placeholder": "​",
            "style": "IPY_MODEL_0648d32f340641f69ab8101d54b26046",
            "value": " 436k/436k [00:00&lt;00:00, 625kB/s]"
          }
        },
        "f1f892a8cb5b42f8bd840ea14c0e7a97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6d36fe088ef41709e0feb59b2cd091a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4e0a79c3b324f409bf27de76f8f67e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38c43d16278144138dbfd3dda93133ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1922a73502804ea0accb73306276ae3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3045316b459b4a19a3ec7b59419730d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0648d32f340641f69ab8101d54b26046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}